name: Docker Image CI

on:
  workflow_dispatch:
  
    inputs:
      # Input 1: queried data
      time:
        description: "date: mm-dd-yyyy"
        required: True
        default: 03-04-2022
        
      # Input 2: aggregation of data (pre calculated)
      aggregation:
        type: choice
        required: True
        description: pre-aggregation
        options:
        - TRUE
        - FALSE
        
      # Input 3: country for which results are filtered
      country:
        type: choice
        required: True
        default: US
        options:
        - US
        - Australia
        - Canada
        - France

        
      # Input 4: destinatary
      dest_email:
        description: "destinary email"
        default: "assansanogo@gmail.com"
        required: True
        

    
env:
  GCP_BUCKET: ${{ secrets.GCP_BUCKET }}
  GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
 


jobs:

  STEP1_synchronization:
    runs-on: ubuntu-latest
    permissions: 
      contents: 'read'
      id-token: 'write'
      
    env:
      PROCCESSED_REPORT: "custom_report.csv"
      TOTAL_REPORT: "$(pwd)/out/data/total_report_${{inputs.country}}.csv"
    
    steps: 
    
    - name: 1. Branch checkout
      uses: actions/checkout@v3
      
    # Configure Workload Identity Federation via a credentials file.
    - id: 'auth'
      name: 2. Authentication to GCP
      uses: 'google-github-actions/auth@v0'
      with:
        workload_identity_provider: 'projects/372976581437/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
        service_account: 'streamliner@my-training-as.iam.gserviceaccount.com'
        
        
    - id: 'folders_structure'
      name: 3. Folder creation before syncing
      run: |
        mkdir -p $(pwd)/out/data/${{github.event.inputs.country}}
      
    - id: 'sync'
      name: 4. Sync with remote bucket  
      uses: actions-hub/gcloud@master 
      env:
        PROJECT_ID: my-training-as
        APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      with:
        args: rsync -r  gs://streamliner-john-hopkins/${{ github.event.inputs.country }} $(pwd)/out/data/${{ github.event.inputs.country }}
        cli:  gsutil
        
    - name: 5. Safety check (for debug)
      run: |
        cat  $(pwd)/out/data/${{github.event.inputs.country}}/hiddenfile.csv
    
    - name: 6. Temporary datastore (artifact)
      uses: actions/upload-artifact@v3
      with:
        name: cumulative_report
        path: out/data/${{github.event.inputs.country}}/hiddenfile.csv


  STEP2_streamline:
    runs-on: ubuntu-latest
    needs: STEP1_synchronization
    
    steps:
    - uses: actions/checkout@v3
    
    - id: 'sync'
      name: 1. Folder creation before syncing
      run: |
        mkdir -p $(pwd)/out/data/${{github.event.inputs.country}}
        echo "DATE=$(date +'%m-%d-%Y')" >> $GITHUB_ENV
        
    - name: 2. Data retrieval for previously fetched cumulative report (artifact from previous step)
      uses: actions/download-artifact@v3
      with:
        name: cumulative_report

    #- id: checks
    #  name: check dest folder
    #  run: |
    #    echo $(ls -l $(pwd)/out)
      
    - id: 'img_builder'
      name: 4. Docker image construction
      run: docker build . --file Dockerfile --tag streamliner:latest
     
    - id: 'docker_runner'
      name: 4. Docker container execution
      run: |
        docker run -t --rm -v $(pwd)/out:/app/out  \
        -e DATE=$(date +'%m-%d-%Y') \
        -e AGGREGATION=FALSE \
        -e COUNTRY=US  \
        -e PROCESSED_REPORT_PATH=out/data/${{github.event.inputs.country}}/$(date +'%m-%d-%Y')_pre_aggregation_FALSE_report.csv \
        -e TOTAL_REPORT_PATH=out/data/${{github.event.inputs.country}}/hiddenfile.csv \
        -e OUTPUT_REPORT_PATH="out/data/${{github.event.inputs.country}}/$(date +'%m-%d-%Y')_to_upload.csv" \
        streamliner:latest
        
    - name: 5. INFO - Describe the requested date
      run: echo "the workflow will retrieve data before:" ${{github.event.inputs.time}}
      
    - name: 6. INFO - Describe the level of aggregation
      run: echo "the workflow will retrieve pre-aggregated data:" ${{github.event.inputs.aggregation}}
      
    - name: 7 INFO - Describe the chosen country for summarization
      run: echo "the workflow will summarize the chosen country:" ${{github.event.inputs.country}} 
    
    #- id: daterun
    #  name: Run Docker container (with inputs)
    #  run: docker run -t --rm -v $(pwd)/out:/app/out  -e DATE=${{github.event.inputs.time}} -e COUNTRY=${{github.event.inputs.country}} -e AGGREGATION=${{github.event.inputs.aggregation}} streamliner:latest                                                   
    
    #- name: outputday
      
        
    #  run: | 
    #    echo $(ls  $(pwd)/out) 
    #    REPORT=$(echo $(ls  $(pwd)/out) | head -1)
    #    cp $(pwd)/out/$REPORT custom_report.csv
    #    cat custom_report.csv

    - name: 8. Data storage for final report (artifact)
      uses: actions/upload-artifact@v3
      with:
          name: report
          path: "out/data/${{github.event.inputs.country}}/${{env.DATE}}_to_upload.csv"
 
    - name: 9. Send email through SendGrid (gmail only)
      env:
        SENDER_EMAIL: 'assansanogo@gmail.com'
        DEST_EMAIL: ${{ github.event.inputs.dest_email }}
        SENDGRID_API_KEY: ${{ secrets.SENDGRID }}

          
      run: |
        echo "$SENDGRID_API_KEY"
        sudo apt-get update && sudo apt-get install python3-pip wkhtmltopdf
        pip3 install sendgrid pdfkit glob2

        echo ls $(pwd)/out/data/${{github.event.inputs.country}}/*aggregation*.csv
        PREVIOUS_DAY_CSV=$(echo ls $(pwd)/out/data/${{github.event.inputs.country}}/*aggregation*.csv)
        
        python3 ./streamliner.py "$SENDGRID_API_KEY" ${{ env.SENDER_EMAIL }} ${{ env.DEST_EMAIL }} "$PREVIOUS_DAY_CSV"
      
  STEP3_upload:
    needs: STEP2_streamline
    runs-on: ubuntu-latest
    permissions: 
      contents: 'read'
      id-token: 'write'
          
    steps:
    - uses: actions/checkout@v3
  
        
    - id: 'set_env'
      name: 1. Set environment
      run: |
        echo "DATE=$(date +'%m-%d-%Y')" >> $GITHUB_ENV
        mkdir -p out/data/${{github.event.inputs.country}}
        
    - name: 2. Data retrieval for final report (artifact)
      uses: actions/download-artifact@v3
      with:
        name: report
    
    # Configure Workload Identity Federation via a credentials file.
    - id: 'auth'
      name: 3. Authenticate to GCP
      uses: 'google-github-actions/auth@v0'
      with: 
        workload_identity_provider: 'projects/372976581437/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
        service_account: 'streamliner@my-training-as.iam.gserviceaccount.com'

    - name: 4. bucket upload
      uses: 'google-github-actions/upload-cloud-storage@v0'
      with:
          path: "out/data/${{github.event.inputs.country}}/${{env.DATE}}_to_upload.csv"
          destination: 'streamliner-john-hopkins'
          
    - name: 5. safety check (debug)  
      uses: actions-hub/gcloud@master
      env:
        PROJECT_ID: my-training-as
        APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      with:
        args: list gs://streamliner-john-hopkins/${{github.event.inputs.country}}
        cli: gsutil
