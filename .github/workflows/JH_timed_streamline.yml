name: JH timed Streamline

on:
  schedule:
    - cron: "50 * * * *"
  
  workflow_dispatch:
          
env:
  GCP_BUCKET: ${{ secrets.GCP_BUCKET }}
  GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
  COUNTRY: US
  DEST_EMAIL: 'assansanogo@gmail.com'
  PRE_AGGREGATION: 'FALSE'
  SENDER_EMAIL: 'assansanogo@gmail.com' # <youremail>
  SENDGRID_API_KEY: ${{ secrets.SENDGRID }}
 
jobs:

  STEP1_synchronization:
    runs-on: ubuntu-latest
    permissions: 
      contents: 'read'
      id-token: 'write'
      
    env:
      PROCESSED_REPORT: "custom_report.csv"

  
    steps: 
    
    - name: 1. Branch checkout
      uses: actions/checkout@v3
      
    # Configure Workload Identity Federation via a credentials file.
    - name: 2. Authentication to GCP
      uses: 'google-github-actions/auth@v0'
      with:
        workload_identity_provider: 'projects/372976581437/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
        service_account: 'streamliner@my-training-as.iam.gserviceaccount.com'
        
        
    - name: 3. Folder creation before syncing
      run: |
        mkdir -p $(pwd)/out/data/${{env.COUNTRY}}
        echo "TOTAL_REPORT=$(pwd)/out/data/total_report_${{env.COUNTRY}}.csv" >> $GITHUB_ENV
        
      
    - name: 4. Sync with remote bucket  
      uses: actions-hub/gcloud@master 
      env:
        PROJECT_ID: my-training-as
        APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      with:
        args: rsync -r  gs://streamliner-john-hopkins/${{ env.COUNTRY }} $(pwd)/out/data/${{ env.COUNTRY }}
        cli:  gsutil
        
    - name: 5. Safety check (debug checkpoint)
      run: |
        cat  $(pwd)/out/data/${{ env.COUNTRY }}/consolidated.csv
    
    - name: 6. Temporary datastore (artifact)
      uses: actions/upload-artifact@v3
      with:
        name: previous_reports
        path: out/data/${{ env.COUNTRY }}/consolidated.csv


  STEP2_streamline:
    runs-on: ubuntu-latest
    needs: STEP1_synchronization
    
    steps:
    - uses: actions/checkout@v3
    
    - name: 1. Folder creation before syncing
      run: |
        mkdir -p $(pwd)/out/data/${{env.COUNTRY}}
        
    - name: 2. set_timezone (LA by default)
      uses: szenius/set-timezone@v1.0
      with:
          timezoneLinux: "America/Los_Angeles"
        
    - name: 3. Dynamic environment variable setting (DATE)
      run: |
        mkdir -p $(pwd)/out/data/${{ env.COUNTRY }}
        echo "DATE=$(date +'%m-%d-%Y')" >> $GITHUB_ENV
        
    - name: 4. Data retrieval for previously fetched cumulative report (artifact from previous step)
      uses: actions/download-artifact@v3
      with:
        name: previous_reports

    - name: 5. check destination folder of the artifact
      run: |
        echo $(ls /home/runner/work/moretestgithubactions/moretestgithubactions/*)
        cp /home/runner/work/moretestgithubactions/moretestgithubactions/consolidated.csv  \
          $(pwd)/out/data/${{ env.COUNTRY }}/consolidated.csv
      
    - name: 6. Docker image construction
      run: docker build . --file Dockerfile --tag streamliner:latest
     
    - name: 7. Docker container execution
      run: |
        docker run -t --rm -v $(pwd)/out:/app/out  \
        -e DATE=${{ env.DATE }} \
        -e AGGREGATION=FALSE \
        -e COUNTRY=US  \
        -e PROCESSED_REPORT_PATH=out/data/${{ env.COUNTRY }}/${{ env.DATE }}_pre_aggregation_${{ env.PRE_AGGREGATION }}_report.csv \
        -e TOTAL_REPORT_PATH=./out/data/${{ env.COUNTRY }}/consolidated.csv \
        -e OUTPUT_REPORT_PATH="./out/data/${{ env.COUNTRY }}/${{ env.DATE }}_to_upload.csv" \
        streamliner:latest
        
    
    
    - name: 8. INFO - Describe the paths & files
      run: |
        echo $(ls .)
        echo $(ls out/data)
        echo $(ls out/data/US)
      
    - name: 9. Data storage for final report (artifact)
      uses: actions/upload-artifact@v3
      with:
          name: consolidated_report_${{ env.DATE }}
          path: "out/data/${{ env.COUNTRY }}/${{ env.DATE }}_to_upload.csv"
 
    - name: 10. Send email through SendGrid (gmail only)
          
      run: |
        echo "$SENDGRID_API_KEY"
        sudo apt-get update && sudo apt-get install python3-pip wkhtmltopdf
        pip3 install sendgrid pdfkit glob2
        echo $(ls $(pwd)/out/data/${{ env.COUNTRY }}/*aggregation*.csv)
        
        PREVIOUS_DAY_CSV=$(echo ls $(pwd)/out/data/${{ env.COUNTRY }}/*aggregation*.csv)
        
        python3 ./streamliner.py "$SENDGRID_API_KEY" ${{ env.SENDER_EMAIL }} ${{ env.DEST_EMAIL }} "$PREVIOUS_DAY_CSV"
      
  
  STEP3_upload:
  
    needs: STEP2_streamline
    runs-on: ubuntu-latest
    permissions: 
      contents: 'read'
      id-token: 'write'
          
    steps:
    - uses: actions/checkout@v3
    
    - name: 1. set_timezone (LA by default)
      uses: szenius/set-timezone@v1.0
      with:
          timezoneLinux: "America/Los_Angeles"

    - name: 2. Set environment (date + project structure)
      run: |
        echo "DATE=$(date +'%m-%d-%Y')" >> $GITHUB_ENV
        mkdir -p out/data/${{github.event.inputs.country}}
        
    - name: 3. Data retrieval for final report (artifact)
      uses: actions/download-artifact@v3
      with:
        name: consolidated_report_${{ env.DATE }}
    
    - name: 4. Authenticate to GCP (Auth through Workload Identity Federation - Method 1)
      uses: 'google-github-actions/auth@v0'
      with: 
        workload_identity_provider: 'projects/372976581437/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
        service_account: 'streamliner@my-training-as.iam.gserviceaccount.com'
        
    - name: 5. Copy artifact file to working directory
      run: |
        ls /home/runner/work/moretestgithubactions/moretestgithubactions
        cp /home/runner/work/moretestgithubactions/moretestgithubactions/${{ env.DATE }}_to_upload.csv out/data/consolidated.csv
          
    - name: 6. Authenticate to GCP & Copy consolidated file with gsutil (Auth through Workload Identity Federation - Method 2) 
      uses: actions-hub/gcloud@master
      env:
        PROJECT_ID: my-training-as
        APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      with:
        args: cp out/data/consolidated.csv gs://streamliner-john-hopkins/${{env.COUNTRY}}
        cli: gsutil
          
    - name: 7. safety check upload verification (debug)  (Auth through Workload Identity Federation - Method 2) 
      uses: actions-hub/gcloud@master
      env:
        PROJECT_ID: my-training-as
        APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      with:
        args: list gs://streamliner-john-hopkins/${{ env.COUNTRY }}
        cli: gsutil
